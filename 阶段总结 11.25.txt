阶段性学习总结-深度学习入门
学习内容简述：
第1章：感知器
-基础概念：介绍了神经网络的最基本单元-感知器。
-核心知识：二元分类、激活函数、权重和偏置的概念。
第2章：线性单元和梯度下降
-线性单元：介绍了一种简单的线性模型，适用于回归问题。
-梯度下降：学习了优化算法的基础，理解如何调整模型参数以最小化损失函数。
第3章：神经网络与反向传播
-多层网络结构：构建了第一个多层神经网络，学习了网络的层次结构。
-反向传播：理解了如何有效地计算梯度并在网络中反向传播。
第4章：卷积神经网络（CNN）
-卷积层原理：探索了卷积层的工作原理，理解了特征提取的概念。
-应用实例：了解了CNN在图像处理和识别任务中的应用。
第5章：循环神经网络（RNN）
-序列数据处理：学习了RNN如何处理时间序列数据或连续数据。
-挑战与解决方案：掌握了处理长序列时的挑战，例如梯度消失问题。
第6章：长短时记忆网络（LSTM）
-LSTM结构：深入学习了LSTM的内部机制，包括门控制和单元状态。
-序列建模：理解了LSTM如何改善RNN在长序列建模方面的性能。
第7章：递归神经网络
-递归结构：探索了递归神经网络如何处理更复杂的序列结构。
-实际应用：了解了递归神经网络在各种复杂应用中的实际用途，如自然语言处理。
学习感悟：
-挑战与克服：开始时感受到难度的激增，但通过不断的实践和问题解决，逐渐克服了困难。
-知识串联：将零散的知识点连接成完整的理解，对深度学习有了更为全面的认识。
-实践的重要性：通过编写代码和实际应用，加深了对理论知识的理解和应用。
一些心里话：
这段时间给我最大的感触是自己学进去了新的东西，这种感觉很享受，每一次代码编写都会遇到不同的问题，每一天的学习对自己都是一种挑战，在整个深度学习的入门学习中我感觉难度梯度是合理的，递增的，感知器，线性单元梯度下降这两张确实没有感觉到什么难度，但是一开始真正架构起神经网络，难度骤升，教程中的代码也并不全，自己手敲时并没有规范的代码书写习惯（现在已经养成），导致困难重重，在不断查看完整标答代码和自己额外学习之后那种吧零碎的知识串连起来的感觉真的很好，第一天的问题和疑惑可以在第二天的学习里得到解答，第二天学到了新的东西去完善昨天的代码形成了巩固，最后第七章结束看着自己的7个py文件里每个class和def都相互呼应调用的感觉真的很好，现在自己要戒骄戒躁，目前的推进速度比自己预想的块，有望12月完成所有学习计划。