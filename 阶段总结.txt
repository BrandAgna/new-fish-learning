阶段总结-2023/11/16
学习背景：
为了提高自己的编程能力和深度学习知识，我在2023年11月初日至今学习了廖雪峰的Git教程、vscode、anaconda、Jupyter、Linux 、深度学习基础-感知器、神经网络和反向传播算法入门、卷积神经网络入门、pytorch-卷积神经网络等内容。
通过阅读教程、观看视频、练习代码、参与讨论等方式，完成了阶段学习。
学习内容：
通过这个阶段的自学，我学习了以下内容：
- 廖雪峰的Git教程：简单易懂的Git教程，讲解了Git的基本概念、常用命令、分支管理、远程仓库、标签管理等内容，让我掌握了Git的使用方法和工作流程。但是git目前仍然不是特别熟练，在commit的时候不是很熟练。
- vscode：一直在用的代码编辑器，支持多种编程语言、主题、插件和调试工具，提供了强大的代码编辑、运行和调试功能，提高了我的开发效率和质量。
- anaconda：这是一个流行的Python数据科学平台，包含了众多的数据分析、机器学习和深度学习的开源包，方便了我的环境管理和包安装，也提供了Jupyter Notebook和Spyder等交互式开发环境。
- Jupyter：这是一个基于Web的交互式计算平台，支持多种编程语言，可以创建和共享包含代码、文本、图像和视频的计算文档，适合进行数据探索、可视化和展示。
- Linux 基础：这是一个自由和开源的类 Unix 操作系统，具有稳定、安全、高效的特点，广泛应用于服务器和嵌入式设备。我学习了Linux的基本概念、文件系统、常用命令、Shell脚本、用户管理、进程管理等内容，掌握了Linux的基本操作和管理方法。
- 深度学习基础-感知器：这是一个最简单的深度学习算法，模拟了人工神经元的结构和功能，可以进行二分类任务。我学习了感知器的原理、数学模型、训练方法和应用场景，理解了深度学习的基本思想和方法。
- 神经网络和反向传播算法入门：这是一个更复杂的深度学习算法，由多个感知器组成多层的网络结构，可以进行多分类和回归任务。我学习了神经网络的结构、激活函数、损失函数、正向传播和反向传播等内容，掌握了神经网络的构建和训练方法。
- 卷积神经网络入门：这是一个针对图像处理的深度学习算法，利用卷积核提取图像的局部特征，具有平移不变性和参数共享的优点，可以进行图像分类、检测、分割等任务。我学习了卷积神经网络的组成、卷积运算、池化运算、全连接层等内容，理解了卷积神经网络的工作原理和特点。
- pytorch-卷积神经网络：为了更好的学习卷积神经网络，搭配着pdf教程文件，观看了对应的视频，配合学习。
学习成果：
通过这个阶段的自学，我取得了以下成果：
- 提高了编程能力，掌握了多种工具和技能。我不仅学会了使用Git进行版本控制，vscode进行代码编辑，anaconda进行环境管理，Jupyter进行交互式计算，Linux进行系统操作，还学会了使用pytorch进行深度学习模型的搭建和训练，为我的编程项目提供了强大的支持和保障。
- 增加了深度学习知识，理解了多种算法和原理。学习了感知器、神经网络和卷积神经网络等基础的深度学习算法，还学习了反向传播、卷积运算、池化运算等核心的深度学习原理，为我的深度学习理论打下了坚实的基础。
- 完成了数个深度学习实例，按照章节完成了对应的习题。
学习反思：
通过这个阶段的自学，我也意识到了自己在以下几方面的困难和问题：
- 缺乏扎实的基础，难以理解和掌握一些原理相关的内容。自己的数学基础比较差，在学习一些原理，公式相关的内容时，我感到很吃力，有时甚至无法理解和掌握，导致学习有些知识和技能还很薄弱和模糊。
- 代码编写不够规范。由于有段时间没有进行代码编写，一些缩进和注释并没有养成习惯，导致我在debug时很费时费力，有时甚至出现一些低级的错误和漏洞，导致代码的质量和效率不高，有些代码还很冗余和混乱。
学习展望：
希望可以在12月中旬完成所有培训计划。