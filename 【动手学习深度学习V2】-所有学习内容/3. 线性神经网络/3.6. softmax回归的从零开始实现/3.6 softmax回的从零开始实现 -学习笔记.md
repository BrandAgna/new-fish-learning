## Softmax回归的从零开始实现

### 3.6.1 初始化模型参数
- 每个样本表示为固定长度向量。图像展平为长度为784的向量。权重构成\(784 \times 10\)矩阵，偏置为\(1 \times 10\)行向量。权重用正态分布初始化，偏置初始化为0。

### 3.6.2 定义softmax操作
- Softmax操作涉及对每个元素求幂，对每行求和得到每个样本的规范化常数，然后将每行除以其规范化常数确保结果和为1。

### 3.6.3 定义模型
- 定义softmax模型后，将输入数据通过网络映射到输出。在传递数据之前，使用`reshape`函数将图像展平为向量。

### 3.6.4 定义损失函数
- 实现交叉熵损失函数，它是深度学习中常用的损失函数，适用于分类问题。交叉熵使用真实标签的预测概率的负对数似然。

### 3.6.5 分类精度
- 分类精度是通过比较预测的类别和实际标签来计算的，表示为正确预测数量与总预测数量之比。

### 3.6.6 训练
- 训练过程包括定义一个函数来训练模型的单个迭代周期。使用`updater`函数更新模型参数。训练包括计算损失、反向传播以及参数更新。

### 3.6.7 评估模型精度
- 对于任意数据迭代器访问的数据集，可以评估任意模型的精度。

