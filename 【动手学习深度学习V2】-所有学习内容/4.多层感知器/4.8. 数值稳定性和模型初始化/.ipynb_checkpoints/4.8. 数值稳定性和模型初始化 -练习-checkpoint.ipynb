{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46131c32",
   "metadata": {},
   "source": [
    "## 练习\n",
    "\n",
    "1. 除了多层感知机的排列对称性之外，还能设计出其他神经网络可能会表现出对称性且需要被打破的情况吗？\n",
    "2. 我们是否可以将线性回归或softmax回归中的所有权重参数初始化为相同的值？\n",
    "3. 在相关资料中查找两个矩阵乘积特征值的解析界。这对确保梯度条件合适有什么启示？\n",
    "4. 如果我们知道某些项是发散的，我们能在事后修正吗？看看关于按层自适应速率缩放的论文 :cite:`You.Gitman.Ginsburg.2017` 。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4634d515",
   "metadata": {},
   "source": [
    "### 练习 1：设计其他神经网络的对称性\n",
    "\n",
    "在神经网络中，除了多层感知机的排列对称性之外，还有其他情况可能会出现对称性，需要被打破，例如：\n",
    "\n",
    "- **卷积神经网络（CNN）**：如果卷积核的所有权重都初始化为相同的值，那么每个卷积核将会提取相同的特征，这会导致对称性问题。需要通过随机初始化来打破这种对称性。\n",
    "- **循环神经网络（RNN）**：在循环神经网络中，如果循环层的权重都初始化为相同的值，那么每个时间步的计算都会变得相同，这也是一种需要避免的对称性。\n",
    "\n",
    "在这些情况中，对权重进行适当的随机初始化是打破对称性并促进模型学习的重要步骤。\n",
    "\n",
    "### 练习 2：权重参数初始化为相同的值\n",
    "\n",
    "在线性回归或softmax回归中，将所有权重参数初始化为相同的值是不理想的，因为这会导致模型在学习过程中的每个特征都被赋予相同的重要性，从而限制了模型的表达能力。此外，这也可能导致梯度下降算法的对称性问题，使得所有权重在训练过程中以相同的方式更新。因此，即使在这些简单的模型中，也通常推荐使用随机初始化的权重。\n",
    "\n",
    "### 练习 3：两个矩阵乘积的特征值界\n",
    "\n",
    "两个矩阵乘积的特征值分析可以揭示有关梯度和模型稳定性的重要信息。例如，如果两个矩阵乘积的特征值中存在非常大的值，这可能导致梯度爆炸的问题；如果特征值非常小，则可能导致梯度消失的问题。确保梯度条件适当意味着我们需要关注权重初始化和网络架构的选择，以避免这些极端情况。\n",
    "\n",
    "### 练习 4：修正发散项\n",
    "\n",
    "如果我们知道某些项在训练过程中可能会发散，我们可以采用一些策略来事后修正，比如按层自适应速率缩放。这种方法可以根据每层的特定情况动态调整学习率，以确保训练的稳定性。例如，对于那些容易导致梯度爆炸或消失的层，可以减小或增大学习率，以帮助稳定训练过程。这种方法需要对训练动态有深入的理解，并可能需要额外的计算资源来监控和调整学习率。按层自适应速率缩放是深度学习中的一个活跃研究领域，旨在提高模型训练的稳定性和效率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973565eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
