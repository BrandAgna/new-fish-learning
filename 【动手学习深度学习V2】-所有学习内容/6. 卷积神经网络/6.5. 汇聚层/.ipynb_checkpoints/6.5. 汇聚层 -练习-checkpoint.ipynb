{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0430bc80",
   "metadata": {},
   "source": [
    "## 练习\n",
    "\n",
    "1. 尝试将平均汇聚层作为卷积层的特殊情况实现。\n",
    "1. 尝试将最大汇聚层作为卷积层的特殊情况实现。\n",
    "1. 假设汇聚层的输入大小为$c\\times h\\times w$，则汇聚窗口的形状为$p_h\\times p_w$，填充为$(p_h, p_w)$，步幅为$(s_h, s_w)$。这个汇聚层的计算成本是多少？\n",
    "1. 为什么最大汇聚层和平均汇聚层的工作方式不同？\n",
    "1. 我们是否需要最小汇聚层？可以用已知函数替换它吗？\n",
    "1. 除了平均汇聚层和最大汇聚层，是否有其它函数可以考虑（提示：回想一下`softmax`）？为什么它不流行？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c486e8",
   "metadata": {},
   "source": [
    "### 1. 尝试将平均汇聚层作为卷积层的特殊情况实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "776c5191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[2., 3.],\n",
      "          [5., 6.]]]], grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class AvgPool2dAsConv2d(nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super(AvgPool2dAsConv2d, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.avg_pool_conv = nn.Conv2d(1, 1, kernel_size=kernel_size, bias=False)\n",
    "        self.avg_pool_conv.weight.data.fill_(1.0 / (kernel_size * kernel_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.avg_pool_conv(x)\n",
    "\n",
    "# 测试\n",
    "input_tensor = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]]).reshape(1, 1, 3, 3)\n",
    "avg_pool_as_conv = AvgPool2dAsConv2d(2)\n",
    "result = avg_pool_as_conv(input_tensor)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c950adc4",
   "metadata": {},
   "source": [
    "### 2. 尝试将最大汇聚层作为卷积层的特殊情况实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07c398ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0., 0.],\n",
      "          [0., 0.]]]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MaxPool2dAsConv2d(nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super(MaxPool2dAsConv2d, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.max_pool_conv = nn.Conv2d(1, 1, kernel_size=kernel_size, bias=True)\n",
    "        \n",
    "        # 设置一个大的负权重和一个大的正偏置\n",
    "        self.max_pool_conv.weight.data.fill_(-1e6)\n",
    "        self.max_pool_conv.bias.data.fill_(1e6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 卷积后应用ReLU激活函数来模拟最大值的选择\n",
    "        return F.relu(self.max_pool_conv(x))\n",
    "\n",
    "# 测试\n",
    "input_tensor = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]]).reshape(1, 1, 3, 3)\n",
    "max_pool_as_conv = MaxPool2dAsConv2d(2)\n",
    "result = max_pool_as_conv(input_tensor)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c92162c",
   "metadata": {},
   "source": [
    "### 3. 汇聚层的计算成本"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b751aa77",
   "metadata": {},
   "source": [
    "汇聚层的计算成本相对较低。具体计算成本取决于汇聚窗口的大小、步幅和填充。每个输出元素的计算涉及$p_h \\times p_w$个操作（最大或平均），总共有 $\\lceil (h - p_h + 2 \\times pad_h) / s_h \\rceil \\times \\lceil (w - p_w + 2 \\times pad_w) / s_w \\rceil$ 个输出元素。因此，总操作数为 $c \\times \\lceil (h - p_h + 2 \\times pad_h) / s_h \\rceil \\times \\lceil (w - p_w + 2 \\times pad_w) / s_w \\rceil \\times p_h \\times p_w$。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc7d65b",
   "metadata": {},
   "source": [
    "### 4. 最大汇聚层和平均汇聚层的工作方式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360a9c66",
   "metadata": {},
   "source": [
    "最大汇聚层和平均汇聚层的主要区别在于它们聚合输入数据的方式。最大汇聚层通过选择汇聚窗口中的最大值来保留最强的信号，而平均汇聚层则计算窗口中所有值的平均值，提供平滑的下采样。这两种方法的选择取决于特定应用的需求。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a40022",
   "metadata": {},
   "source": [
    "### 5. 是否需要最小汇聚层"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f588e7",
   "metadata": {},
   "source": [
    "最小汇聚层在实践中较少使用，因为它倾向于捕获背景信息而非突出特征。如果需要，可以通过对输入数据取负值，然后应用最大汇聚层，最\n",
    "\n",
    "后再取负值来模拟最小汇聚层。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b2c207",
   "metadata": {},
   "source": [
    "### 6. 其他汇聚函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9699f44d",
   "metadata": {},
   "source": [
    "除了最大和平均汇聚，也可以考虑使用其他函数，如L2汇聚（平方后取平均，然后开方）或softmax汇聚。这些方法在特定应用中可能有用，但不如最大和平均汇聚流行，主要是因为它们的计算复杂性更高，且在实践中未必总能提供更好的结果。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
