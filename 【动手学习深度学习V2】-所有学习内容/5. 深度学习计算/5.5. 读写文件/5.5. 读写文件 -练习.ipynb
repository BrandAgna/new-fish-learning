{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ddf6cf8",
   "metadata": {},
   "source": [
    "# 练习\n",
    "\n",
    "1. 即使不需要将经过训练的模型部署到不同的设备上，存储模型参数还有什么实际的好处？\n",
    "1. 假设我们只想复用网络的一部分，以将其合并到不同的网络架构中。比如想在一个新的网络中使用之前网络的前两层，该怎么做？\n",
    "1. 如何同时保存网络架构和参数？需要对架构加上什么限制？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77593b7",
   "metadata": {},
   "source": [
    "## 1. 即使不需要将经过训练的模型部署到不同的设备上，存储模型参数还有什么实际的好处？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98c670a",
   "metadata": {},
   "source": [
    "存储模型参数，即使不部署到不同设备，有以下好处：\n",
    "\n",
    "中断和恢复训练：在长时间或资源密集型训练过程中，能够在训练中断时保存进度，并在之后从断点继续训练。\n",
    "模型分析和优化：通过保存不同训练阶段的模型，可以分析模型在训练过程中的表现和行为，帮助优化模型架构和参数。\n",
    "模型共享：便于与其他研究者或开发者共享模型，促进合作和知识传播。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7227c16",
   "metadata": {},
   "source": [
    "## 2. 假设我们只想复用网络的一部分，以将其合并到不同的网络架构中。比如想在一个新的网络中使用之前网络的前两层，该怎么做？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ea0a79",
   "metadata": {},
   "source": [
    "### 要实现这一点，可以采取以下步骤：\n",
    "    1.加载原始模型：首先，加载完整的预训练模型。\n",
    "    2.创建新模型：然后，定义一个新的网络架构。\n",
    "    3.复制参数：从原始模型中提取前两层的参数，并将它们应用到新模型的对应层上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "161a3cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0966,  0.2798, -0.0664,  0.2176, -0.1254, -0.1364, -0.1728,  0.0633,\n",
      "         -0.1171, -0.0731, -0.6285, -0.5266,  0.1607,  0.1162, -0.0786,  0.1323,\n",
      "         -0.0034,  0.2881,  0.5624, -0.4052],\n",
      "        [ 0.1968, -0.1864,  0.1467,  0.0241,  0.0245,  0.0911, -0.0242, -0.0186,\n",
      "          0.1790, -0.0441, -0.2340, -0.3641,  0.3657, -0.1483,  0.1655,  0.0515,\n",
      "          0.3055,  0.3738,  0.2565,  0.1245]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "## 代码实现\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 定义原始的MLP模型\n",
    "class OriginalMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OriginalMLP, self).__init__()\n",
    "        self.hidden = nn.Linear(20, 256)\n",
    "        self.output = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.output(F.relu(self.hidden(x)))\n",
    "\n",
    "# 定义新的网络模型\n",
    "class NewNet(nn.Module):\n",
    "    def __init__(self, original_model):\n",
    "        super(NewNet, self).__init__()\n",
    "        self.original_hidden = original_model.hidden\n",
    "        # 新网络的其他层\n",
    "        self.new_layer = nn.Linear(256, 20)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.original_hidden(x))\n",
    "        x = self.new_layer(x)\n",
    "        return x\n",
    "\n",
    "# 实例化原始模型并加载预训练参数\n",
    "original_model = OriginalMLP()\n",
    "# 假设有预训练参数\n",
    "# original_model.load_state_dict(torch.load('path_to_pretrained_params'))\n",
    "\n",
    "# 实例化新模型\n",
    "new_net = NewNet(original_model)\n",
    "\n",
    "# 测试新模型\n",
    "X_new = torch.randn(size=(2, 20))\n",
    "Y_new = new_net(X_new)\n",
    "print(Y_new)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743a230b",
   "metadata": {},
   "source": [
    "## 3. 如何同时保存网络架构和参数？需要对架构加上什么限制？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83f30895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4846,  0.6130,  0.1943, -0.0275, -0.5300, -0.1335,  0.1240,  0.2372,\n",
      "         -0.4730, -0.1401],\n",
      "        [ 0.3024, -0.0104,  0.1686, -0.1247, -0.2680,  0.0833,  0.0750,  0.0765,\n",
      "         -0.3465, -0.0357]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 定义MLP模型\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.hidden = nn.Linear(20, 256)\n",
    "        self.output = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.output(F.relu(self.hidden(x)))\n",
    "\n",
    "# 实例化并训练模型（这里仅示例，未实际进行训练）\n",
    "net = MLP()\n",
    "\n",
    "# 保存模型参数和架构信息\n",
    "torch.save({'model_state_dict': net.state_dict(),\n",
    "            'model_class': MLP}, 'model_with_arch.pth')\n",
    "\n",
    "# 加载模型\n",
    "saved_info = torch.load('model_with_arch.pth')\n",
    "model_class = saved_info['model_class']\n",
    "loaded_model = model_class()\n",
    "loaded_model.load_state_dict(saved_info['model_state_dict'])\n",
    "\n",
    "# 测试加载的模型\n",
    "loaded_model.eval()\n",
    "X = torch.randn(size=(2, 20))\n",
    "Y_loaded = loaded_model(X)\n",
    "print(Y_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9e6ee2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
